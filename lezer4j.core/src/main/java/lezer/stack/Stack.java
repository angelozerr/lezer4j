package lezer.stack;

/// A parse stack. These are used internally by the parser to track
/// parsing progress. They also provide some properties and methods
/// that external code such as a tokenizer can use to get information
/// about the parse state.
public class Stack {

	  /// @internal
	  Stack (
	    /// A the parse that this stack is part of @internal
		Parse p,
	    /// Holds state, pos, value stack pos (15 bits array index, 15 bits
	    /// buffer index) triplets for all but the top state
	    /// @internal
	    readonly stack: number[],
	    /// The current parse state @internal
	    public state: number,
	    // The position at which the next reduce should take place. This
	    // can be less than `this.pos` when skipped expressions have been
	    // added to the stack (which should be moved outside of the next
	    // reduction)
	    /// @internal
	    public reducePos: number,
	    /// The input position up to which this stack has parsed.
	    public pos: number,
	    /// The dynamic score of the stack, including dynamic precedence
	    /// and error-recovery penalties
	    /// @internal
	    public score: number,
	    // The output buffer. Holds (type, start, end, size) quads
	    // representing nodes created by the parser, where `size` is
	    // amount of buffer array entries covered by this node.
	    /// @internal
	    readonly buffer: number[],
	    // The base offset of the buffer. When stacks are split, the split
	    // instance shared the buffer history with its parent up to
	    // `bufferBase`, which is the absolute offset (including the
	    // offset of previous splits) into the buffer at which this stack
	    // starts writing.
	    /// @internal
	    readonly bufferBase: number,
	    /// @internal
	    public curContext: StackContext | null,
	    // A parent stack from which this was split off, if any. This is
	    // set up so that it always points to a stack that has some
	    // additional buffer content, never to a stack with an equal
	    // `bufferBase`.
	    /// @internal
	    readonly parent: Stack | null
	  ) {}

	  /// @internal
	  toString() {
	    return `[${this.stack.filter((_, i) => i % 3 == 0).concat(this.state)}]@${this.pos}${this.score ? "!" + this.score : ""}`
	  }

	  // Start an empty stack
	  /// @internal
	  static start(p: Parse, state: number, pos = 0) {
	    let cx = p.parser.context
	    return new Stack(p, [], state, pos, pos, 0, [], 0, cx ? new StackContext(cx, cx.start) : null, null)
	  }

	  /// The stack's current [context](#lezer.ContextTracker) value, if
	  /// any. Its type will depend on the context tracker's type
	  /// parameter, or it will be `null` if there is no context
	  /// tracker.
	  get context() { return this.curContext ? this.curContext.context : null }

	  // Push a state onto the stack, tracking its start position as well
	  // as the buffer base at that point.
	  /// @internal
	  pushState(state: number, start: number) {
	    this.stack.push(this.state, start, this.bufferBase + this.buffer.length)
	    this.state = state
	  }

	  // Apply a reduce action
	  /// @internal
	  reduce(action: number) {
	    let depth = action >> Action.ReduceDepthShift, type = action & Action.ValueMask
	    let {parser} = this.p

	    let dPrec = parser.dynamicPrecedence(type)
	    if (dPrec) this.score += dPrec

	    if (depth == 0) {
	      // Zero-depth reductions are a special caseâ€”they add stuff to
	      // the stack without popping anything off.
	      if (type < parser.minRepeatTerm) this.storeNode(type, this.reducePos, this.reducePos, 4, true)
	      this.pushState(parser.getGoto(this.state, type, true), this.reducePos)
	      this.reduceContext(type)
	      return
	    }

	    // Find the base index into `this.stack`, content after which will
	    // be dropped. Note that with `StayFlag` reductions we need to
	    // consume two extra frames (the dummy parent node for the skipped
	    // expression and the state that we'll be staying in, which should
	    // be moved to `this.state`).
	    let base = this.stack.length - ((depth - 1) * 3) - (action & Action.StayFlag ? 6 : 0)
	    let start = this.stack[base - 2]
	    let bufferBase = this.stack[base - 1], count = this.bufferBase + this.buffer.length - bufferBase
	    // Store normal terms or `R -> R R` repeat reductions
	    if (type < parser.minRepeatTerm || (action & Action.RepeatFlag)) {
	      let pos = parser.stateFlag(this.state, StateFlag.Skipped) ? this.pos : this.reducePos
	      this.storeNode(type, start, pos, count + 4, true)
	    }
	    if (action & Action.StayFlag) {
	      this.state = this.stack[base]
	    } else {
	      let baseStateID = this.stack[base - 3]
	      this.state = parser.getGoto(baseStateID, type, true)
	    }
	    while (this.stack.length > base) this.stack.pop()
	    this.reduceContext(type)
	  }

	  // Shift a value into the buffer
	  /// @internal
	  storeNode(term: number, start: number, end: number, size = 4, isReduce = false) {
	    if (term == Term.Err) { // Try to omit/merge adjacent error nodes
	      let cur: Stack | null = this, top = this.buffer.length
	      if (top == 0 && cur.parent) {
	        top = cur.bufferBase - cur.parent.bufferBase
	        cur = cur.parent
	      }
	      if (top > 0 && cur.buffer[top - 4] == Term.Err && cur.buffer[top - 1] > -1) {
	        if (start == end) return
	        if (cur.buffer[top - 2] >= start) { cur.buffer[top - 2] = end; return }
	      }
	    }

	    if (!isReduce || this.pos == end) { // Simple case, just append
	      this.buffer.push(term, start, end, size)
	    } else { // There may be skipped nodes that have to be moved forward
	      let index = this.buffer.length
	      if (index > 0 && this.buffer[index - 4] != Term.Err) while (index > 0 && this.buffer[index - 2] > end) {
	        // Move this record forward
	        this.buffer[index] = this.buffer[index - 4]
	        this.buffer[index + 1] = this.buffer[index - 3]
	        this.buffer[index + 2] = this.buffer[index - 2]
	        this.buffer[index + 3] = this.buffer[index - 1]
	        index -= 4
	        if (size > 4) size -= 4
	      }
	      this.buffer[index] = term
	      this.buffer[index + 1] = start
	      this.buffer[index + 2] = end
	      this.buffer[index + 3] = size
	    }
	  }

	  // Apply a shift action
	  /// @internal
	  shift(action: number, next: number, nextEnd: number) {
	    if (action & Action.GotoFlag) {
	      this.pushState(action & Action.ValueMask, this.pos)
	    } else if ((action & Action.StayFlag) == 0) { // Regular shift
	      let start = this.pos, nextState = action, {parser} = this.p
	      if (nextEnd > this.pos || next <= parser.maxNode) {
	        this.pos = nextEnd
	        if (!parser.stateFlag(nextState, StateFlag.Skipped)) this.reducePos = nextEnd
	      }
	      this.pushState(nextState, start)
	      if (next <= parser.maxNode) this.buffer.push(next, start, nextEnd, 4)
	      this.shiftContext(next)
	    } else { // Shift-and-stay, which means this is a skipped token
	      if (next <= this.p.parser.maxNode) this.buffer.push(next, this.pos, nextEnd, 4)
	      this.pos = nextEnd
	    }
	  }

	  // Apply an action
	  /// @internal
	  apply(action: number, next: number, nextEnd: number) {
	    if (action & Action.ReduceFlag) this.reduce(action)
	    else this.shift(action, next, nextEnd)
	  }

	  // Add a prebuilt node into the buffer. This may be a reused node or
	  // the result of running a nested parser.
	  /// @internal
	  useNode(value: Tree | TreeBuffer, next: number) {
	    let index = this.p.reused.length - 1
	    if (index < 0 || this.p.reused[index] != value) {
	      this.p.reused.push(value)
	      index++
	    }
	    let start = this.pos
	    this.reducePos = this.pos = start + value.length
	    this.pushState(next, start)
	    this.buffer.push(index, start, this.reducePos, -1 /* size < 0 means this is a reused value */)
	    if (this.curContext) this.updateContext(this.curContext.tracker.reuse(this.curContext.context, value, this.p.input, this))
	  }

	  // Split the stack. Due to the buffer sharing and the fact
	  // that `this.stack` tends to stay quite shallow, this isn't very
	  // expensive.
	  /// @internal
	  split() {
	    let parent: Stack | null = this
	    let off = parent.buffer.length
	    // Because the top of the buffer (after this.pos) may be mutated
	    // to reorder reductions and skipped tokens, and shared buffers
	    // should be immutable, this copies any outstanding skipped tokens
	    // to the new buffer, and puts the base pointer before them.
	    while (off > 0 && parent.buffer[off - 2] > parent.reducePos) off -= 4
	    let buffer = parent.buffer.slice(off), base = parent.bufferBase + off
	    // Make sure parent points to an actual parent with content, if there is such a parent.
	    while (parent && base == parent.bufferBase) parent = parent.parent
	    return new Stack(this.p, this.stack.slice(), this.state, this.reducePos, this.pos,
	                     this.score, buffer, base, this.curContext, parent)
	  }

	  // Try to recover from an error by 'deleting' (ignoring) one token.
	  /// @internal
	  recoverByDelete(next: number, nextEnd: number) {
	    let isNode = next <= this.p.parser.maxNode
	    if (isNode) this.storeNode(next, this.pos, nextEnd)
	    this.storeNode(Term.Err, this.pos, nextEnd, isNode ? 8 : 4)
	    this.pos = this.reducePos = nextEnd
	    this.score -= Recover.Delete
	  }

	  /// Check if the given term would be able to be shifted (optionally
	  /// after some reductions) on this stack. This can be useful for
	  /// external tokenizers that want to make sure they only provide a
	  /// given token when it applies.
	  canShift(term: number) {
	    for (let sim = new SimulatedStack(this);;) {
	      let action = this.p.parser.stateSlot(sim.top, ParseState.DefaultReduce) || this.p.parser.hasAction(sim.top, term)
	      if ((action & Action.ReduceFlag) == 0) return true
	      if (action == 0) return false
	      sim.reduce(action)
	    }
	  }

	  /// Find the start position of the rule that is currently being parsed.
	  get ruleStart() {
	    for (let state = this.state, base = this.stack.length;;) {
	      let force = this.p.parser.stateSlot(state, ParseState.ForcedReduce)
	      if (!(force & Action.ReduceFlag)) return 0
	      base -= 3 * (force >> Action.ReduceDepthShift)
	      if ((force & Action.ValueMask) < this.p.parser.minRepeatTerm)
	        return this.stack[base + 1]
	      state = this.stack[base]
	    }
	  }

	  /// Find the start position of an instance of any of the given term
	  /// types, or return `null` when none of them are found.
	  ///
	  /// **Note:** this is only reliable when there is at least some
	  /// state that unambiguously matches the given rule on the stack.
	  /// I.e. if you have a grammar like this, where the difference
	  /// between `a` and `b` is only apparent at the third token:
	  ///
	  ///     a { b | c }
	  ///     b { "x" "y" "x" }
	  ///     c { "x" "y" "z" }
	  ///
	  /// Then a parse state after `"x"` will not reliably tell you that
	  /// `b` is on the stack. You _can_ pass `[b, c]` to reliably check
	  /// for either of those two rules (assuming that `a` isn't part of
	  /// some rule that includes other things starting with `"x"`).
	  ///
	  /// When `before` is given, this keeps scanning up the stack until
	  /// it finds a match that starts before that position.
	  ///
	  /// Note that you have to be careful when using this in tokenizers,
	  /// since it's relatively easy to introduce data dependencies that
	  /// break incremental parsing by using this method.
	  startOf(types: readonly number[], before?: number) {
	    let state = this.state, frame = this.stack.length, {parser} = this.p
	    for (;;) {
	      let force = parser.stateSlot(state, ParseState.ForcedReduce)
	      let depth = force >> Action.ReduceDepthShift, term = force & Action.ValueMask
	      if (types.indexOf(term) > -1) {
	        let base = frame - (3 * (force >> Action.ReduceDepthShift)), pos = this.stack[base + 1]
	        if (before == null || before > pos) return pos
	      }
	      if (frame == 0) return null
	      if (depth == 0) {
	        frame -= 3
	        state = this.stack[frame]
	      } else {
	        frame -= 3 * (depth - 1)
	        state = parser.getGoto(this.stack[frame - 3], term, true)
	      }
	    }
	  }

	  // Apply up to Recover.MaxNext recovery actions that conceptually
	  // inserts some missing token or rule.
	  /// @internal
	  recoverByInsert(next: number): Stack[] {
	    if (this.stack.length >= Recover.MaxInsertStackDepth) return []

	    let nextStates = this.p.parser.nextStates(this.state)
	    if (nextStates.length > Recover.MaxNext << 1 || this.stack.length >= Recover.DampenInsertStackDepth) {
	      let best = []
	      for (let i = 0, s; i < nextStates.length; i += 2) {
	        if ((s = nextStates[i + 1]) != this.state && this.p.parser.hasAction(s, next))
	          best.push(nextStates[i], s)
	      }
	      if (this.stack.length < Recover.DampenInsertStackDepth)
	        for (let i = 0; best.length < Recover.MaxNext << 1 && i < nextStates.length; i += 2) {
	          let s = nextStates[i + 1]
	          if (!best.some((v, i) => (i & 1) && v == s)) best.push(nextStates[i], s)
	        }
	      nextStates = best
	    }
	    let result: Stack[] = []
	    for (let i = 0; i < nextStates.length && result.length < Recover.MaxNext; i += 2) {
	      let s = nextStates[i + 1]
	      if (s == this.state) continue
	      let stack = this.split()
	      stack.storeNode(Term.Err, stack.pos, stack.pos, 4, true)
	      stack.pushState(s, this.pos)
	      stack.shiftContext(nextStates[i])
	      stack.score -= Recover.Insert
	      result.push(stack)
	    }
	    return result
	  }

	  // Force a reduce, if possible. Return false if that can't
	  // be done.
	  /// @internal
	  forceReduce() {
	    let reduce = this.p.parser.stateSlot(this.state, ParseState.ForcedReduce)
	    if ((reduce & Action.ReduceFlag) == 0) return false
	    if (!this.p.parser.validAction(this.state, reduce)) {
	      this.storeNode(Term.Err, this.reducePos, this.reducePos, 4, true)
	      this.score -= Recover.Reduce
	    }
	    this.reduce(reduce)
	    return true
	  }

	  /// @internal
	  forceAll() {
	    while (!this.p.parser.stateFlag(this.state, StateFlag.Accepting) && this.forceReduce()) {}
	    return this
	  }

	  /// Check whether this state has no further actions (assumed to be a direct descendant of the
	  /// top state, since any other states must be able to continue
	  /// somehow). @internal
	  get deadEnd() {
	    if (this.stack.length != 3) return false
	    let {parser} = this.p
	    return parser.data[parser.stateSlot(this.state, ParseState.Actions)] == Seq.End &&
	      !parser.stateSlot(this.state, ParseState.DefaultReduce)
	  }

	  /// Restart the stack (put it back in its start state). Only safe
	  /// when this.stack.length == 3 (state is directly below the top
	  /// state). @internal
	  restart() {
	    this.state = this.stack[0]
	    this.stack.length = 0
	  }

	  /// @internal
	  sameState(other: Stack) {
	    if (this.state != other.state || this.stack.length != other.stack.length) return false
	    for (let i = 0; i < this.stack.length; i += 3)
	      if (this.stack[i] != other.stack[i]) return false
	    return true
	  }

	  /// Get the parser used by this stack.
	  get parser() { return this.p.parser }

	  /// Test whether a given dialect (by numeric ID, as exported from
	  /// the terms file) is enabled.
	  dialectEnabled(dialectID: number) { return this.p.parser.dialect.flags[dialectID] }

	  private shiftContext(term: number) {
	    if (this.curContext)
	      this.updateContext(this.curContext.tracker.shift(this.curContext.context, term, this.p.input, this))
	  }

	  private reduceContext(term: number) {
	    if (this.curContext)
	      this.updateContext(this.curContext.tracker.reduce(this.curContext.context, term, this.p.input, this))
	  }

	  /// @internal
	  emitContext() {
	    let cx = this.curContext!
	    if (!cx.tracker.strict) return
	    let last = this.buffer.length - 1
	    if (last < 0 || this.buffer[last] != -2)
	      this.buffer.push(cx.hash, this.reducePos, this.reducePos, -2)
	  }

	  private updateContext(context: any) {
	    if (context != this.curContext!.context) {
	      let newCx = new StackContext(this.curContext!.tracker, context)
	      if (newCx.hash != this.curContext!.hash) this.emitContext()
	      this.curContext = newCx
	    }
	  }
}
